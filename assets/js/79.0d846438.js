(window.webpackJsonp=window.webpackJsonp||[]).push([[79],{530:function(t,s,a){"use strict";a.r(s);var n=a(31),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"try-catch的使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#try-catch的使用"}},[t._v("#")]),t._v(" try-catch的使用")]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#前置"}},[t._v("前置")])]),a("li",[a("a",{attrs:{href:"#嵌套使用"}},[t._v("嵌套使用")]),a("ul",[a("li",[a("a",{attrs:{href:"#uninitialized-copy-fill-系列"}},[t._v("uninitialized-[copy+fill]系列")])]),a("li",[a("a",{attrs:{href:"#vector-m-insert-aux-的使用"}},[t._v("vector _M_insert_aux 的使用")])])])]),a("li",[a("a",{attrs:{href:"#嵌套使用总结"}},[t._v("嵌套使用总结")]),a("ul",[a("li",[a("a",{attrs:{href:"#分两步"}},[t._v("分两步")])]),a("li",[a("a",{attrs:{href:"#使用位置标记"}},[t._v("使用位置标记")])])])])])]),a("p"),t._v(" "),a("h1",{attrs:{id:"try-catch保证数据完整性。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#try-catch保证数据完整性。"}},[t._v("#")]),t._v(" try-catch保证数据完整性。")]),t._v(" "),a("h2",{attrs:{id:"前置"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#前置"}},[t._v("#")]),t._v(" 前置")]),t._v(" "),a("p",[t._v("在stl中，对于uninitialized系列函数实现中真正的功能函数位置其实有加入错误处理机制。")]),t._v(" "),a("p",[t._v("使用try-catch结构用来保证写入数据的完整性，如果中间某一个失败 那么会将所有数据都销毁。")]),t._v(" "),a("p",[t._v("比如以下这个：")]),t._v(" "),a("div",{staticClass:"language-cpp line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_ForwardIter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_Tp")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__uninitialized_fill_aux")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ForwardIter __first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _ForwardIter __last"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                              "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" _Tp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("__x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __false_type"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  _ForwardIter __cur "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" __first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  __STL_TRY "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" __cur "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" __last"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("__cur"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_Construct")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("__cur"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__STL_UNWIND")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_Destroy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __cur"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br")])]),a("p",[t._v("相关的两个宏定义:")]),t._v(" "),a("div",{staticClass:"language-cpp line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[a("span",{pre:!0,attrs:{class:"token macro property"}},[a("span",{pre:!0,attrs:{class:"token directive-hash"}},[t._v("#")]),a("span",{pre:!0,attrs:{class:"token directive keyword"}},[t._v("define")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token macro-name"}},[t._v("__STL_TRY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token expression"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")])])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token macro property"}},[a("span",{pre:!0,attrs:{class:"token directive-hash"}},[t._v("#")]),a("span",{pre:!0,attrs:{class:"token directive keyword"}},[t._v("define")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token macro-name function"}},[t._v("__STL_UNWIND")]),a("span",{pre:!0,attrs:{class:"token expression"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("                                                   ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token expression"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("                                                                ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token expression"}},[t._v("action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("                                                                    ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token expression"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("                                                                     ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token expression"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])])]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br")])]),a("p",[t._v("注意这个throw直接使用，会放弃当前的错误处理阶段，并直接将这个错误向上传到上级函数内进行处理，如果上层函数没有进行处理，那么会中断整个程序的运行。")]),t._v(" "),a("h2",{attrs:{id:"嵌套使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#嵌套使用"}},[t._v("#")]),t._v(" 嵌套使用")]),t._v(" "),a("h3",{attrs:{id:"uninitialized-copy-fill-系列"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#uninitialized-copy-fill-系列"}},[t._v("#")]),t._v(" uninitialized-[copy+fill]系列")]),t._v(" "),a("p",[t._v("在实现 uninitialized系列函数以后，又实现了三个嵌套函数，copy-copy, copy-fill, fill-copy。定义如下：")]),t._v(" "),a("div",{staticClass:"language-cpp line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// __uninitialized_copy_copy")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Copies [first1, last1) into [result, result + (last1 - first1)), and")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//  copies [first2, last2) into")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//  [result, result + (last1 - first1) + (last2 - first2)).")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_InputIter1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_InputIter2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_ForwardIter")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("inline")]),t._v(" _ForwardIter\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__uninitialized_copy_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_InputIter1 __first1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _InputIter1 __last1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          _InputIter2 __first2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _InputIter2 __last2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          _ForwardIter __result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  _ForwardIter __mid "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__first1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __last1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  __STL_TRY "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__first2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __last2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__STL_UNWIND")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_Destroy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// __uninitialized_fill_copy")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Fills [result, mid) with x, and copies [first, last) into")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//  [mid, mid + (last - first)).")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_ForwardIter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_Tp")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_InputIter")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("inline")]),t._v(" _ForwardIter\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__uninitialized_fill_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ForwardIter __result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _ForwardIter __mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" _Tp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("__x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _InputIter __first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          _InputIter __last"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_fill")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  __STL_TRY "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __last"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__STL_UNWIND")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_Destroy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// __uninitialized_copy_fill")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Copies [first1, last1) into [first2, first2 + (last1 - first1)), and")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//  fills [first2 + (last1 - first1), last2) with x.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("template")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_InputIter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_ForwardIter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_Tp")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("inline")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__uninitialized_copy_fill")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_InputIter __first1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _InputIter __last1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                      _ForwardIter __first2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                      _ForwardIter __last2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" _Tp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("__x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  _ForwardIter __mid2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__first1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __last1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __first2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  __STL_TRY "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_fill")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__mid2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __last2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__STL_UNWIND")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_Destroy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__first2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __mid2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br"),a("span",{staticClass:"line-number"},[t._v("33")]),a("br"),a("span",{staticClass:"line-number"},[t._v("34")]),a("br"),a("span",{staticClass:"line-number"},[t._v("35")]),a("br"),a("span",{staticClass:"line-number"},[t._v("36")]),a("br"),a("span",{staticClass:"line-number"},[t._v("37")]),a("br"),a("span",{staticClass:"line-number"},[t._v("38")]),a("br"),a("span",{staticClass:"line-number"},[t._v("39")]),a("br")])]),a("p",[t._v("其实三个的定义是类似的。")]),t._v(" "),a("p",[t._v("但是要注意一个点，目前期望保护的是完整的整个数据，")]),t._v(" "),a("p",[t._v("我们通过copy_fill来表示，首先将first1-last1复制到first2-mid, 然后使用x 填充mid-last2,")]),t._v(" "),a("p",[t._v("其实对于copy和fill内部都有实现错误处理，也就是我们的first2-mid和mid-last2都是安全的，但是对于这两者的衔接还需要一个try-catch来表示。")]),t._v(" "),a("p",[t._v("于是，")]),t._v(" "),a("ul",[a("li",[t._v("首先获取第一段copy，如果copy出问题那么会将first2-mid完全销毁并向上传输错误，由于这个位置没有错误处理，于是直接程序中断，这是安全的。")]),t._v(" "),a("li",[t._v("然后进入fill， 这一段如果出错那么 mid-last2也会销毁，但是同时我们还要销毁first2-mid， 于是这一段套在try-catch中，如果出现错误，那么在catch中销毁first2-mid,")])]),t._v(" "),a("h3",{attrs:{id:"vector-m-insert-aux-的使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#vector-m-insert-aux-的使用"}},[t._v("#")]),t._v(" vector "),a("code",[t._v("_M_insert_aux")]),t._v(" 的使用")]),t._v(" "),a("p",[t._v("在vector中也有一个类似的位置。")]),t._v(" "),a("p",[t._v("在内存不够进行扩容时， 会调用"),a("code",[t._v("_M_insert_aux")]),t._v("函数，")]),t._v(" "),a("p",[t._v("这个函数就是先对前面的进行复制， 然后插入一个元素，再对后面的进行复制， 我们也可以看到对应的try-catch结构")]),t._v(" "),a("div",{staticClass:"language-cpp line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[t._v("\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" size_type __old_size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" size_type __len "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" __old_size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" __old_size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    iterator __new_start "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_M_allocate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__len"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    iterator __new_finish "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" __new_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    __STL_TRY "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      __new_finish "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_M_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __position"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __new_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("construct")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__new_finish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("__new_finish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      __new_finish "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("uninitialized_copy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__position"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _M_finish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" __new_finish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__STL_UNWIND")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("destroy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__new_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("__new_finish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_M_deallocate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__new_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("__len"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("destroy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("begin")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("end")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("_M_deallocate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_M_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _M_end_of_storage "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" _M_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    _M_start "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" __new_start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    _M_finish "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" __new_finish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    _M_end_of_storage "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" __new_start "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" __len"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br")])]),a("p",[t._v("这个同样是为了实现出错销毁所有的功能，但是和上一个又有所不同，")]),t._v(" "),a("p",[t._v("注意后面是 "),a("code",[t._v("destroy(__new_start, __new_finish)")]),t._v("，")]),t._v(" "),a("p",[t._v("看起来如果第一步copy出错的话会删除很多，我一开始也以为是个bug，但是其实不是，如果copy出错，则会直接跳到catch位置，这时候其实new_finish等于new_start， 是空的序列。")]),t._v(" "),a("p",[t._v("所以这个时候的__new_finish就类似不嵌套的时候的cur的作用，指示目前位置。")]),t._v(" "),a("h2",{attrs:{id:"嵌套使用总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#嵌套使用总结"}},[t._v("#")]),t._v(" 嵌套使用总结")]),t._v(" "),a("p",[t._v("首先要保证handle函数内是可以完全销毁并继续上抛异常的。")]),t._v(" "),a("h3",{attrs:{id:"分两步"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分两步"}},[t._v("#")]),t._v(" 分两步")]),t._v(" "),a("p",[t._v("首先处理第一段，然后处理第二段，")]),t._v(" "),a("ul",[a("li",[t._v("如果第一段不正常， 则第一段内部销毁函数内处理的数据, 并且上抛的异常没有接收， 程序退出。")]),t._v(" "),a("li",[t._v("如果第一段正常， 则进入第二段，\n"),a("ul",[a("li",[t._v("如果第二段正常，则程序正常向下运行，")]),t._v(" "),a("li",[t._v("如果第二段异常，则第二段内部销毁函数内处理的数据, 并且上抛的异常被处理，销毁[first, mid)")])])])]),t._v(" "),a("div",{staticClass:"language-cpp line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[t._v("mid "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("handle")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tlast "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("handle")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("destroy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br")])]),a("h3",{attrs:{id:"使用位置标记"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用位置标记"}},[t._v("#")]),t._v(" 使用位置标记")]),t._v(" "),a("p",[t._v("首先mid=first，")]),t._v(" "),a("ul",[a("li",[t._v("第一段异常，函数内处理的数据在第一段内部销毁，上抛的异常被处理, 此时mid=first， 销毁[first, first)， 不进行操作。")]),t._v(" "),a("li",[t._v("第一段处理正常， 继续向下\n"),a("ul",[a("li",[t._v("第二段处理正常，程序正常向下运行。")]),t._v(" "),a("li",[t._v("第二段处理异常，第二段内部销毁函数内处理的数据, 上抛的异常被处理， 销毁[first, mid)")])])])]),t._v(" "),a("div",{staticClass:"language-cpp line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[t._v("mid "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tmid "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("handle")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\tlast "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("handle")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("destory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br")])])])}),[],!1,null,null,null);s.default=r.exports}}]);